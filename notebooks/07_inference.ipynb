{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3349651b-c5fb-428d-8143-4ce1187d562c",
   "metadata": {},
   "source": [
    "# Test-Time Inference and Submission Generation\n",
    "\n",
    "This notebook performs end to end inference on the test dataset using the\n",
    "final multimodal model. Satellite image embeddings are extracted using a\n",
    "pretrained CNN and combined with tabular features to generate property\n",
    "price predictions for submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1a8cc-8175-41bd-ba37-a6688327bc91",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We import libraries required for image processing, feature extraction,\n",
    "model loading, and submission file generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573a8dbd-b866-46bc-a742-6a338f23c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744447c8-6421-47b6-8ed2-3c0f9b58ff73",
   "metadata": {},
   "source": [
    "## 2. Loading Test Data\n",
    "\n",
    "The raw test dataset is loaded along with the corresponding satellite\n",
    "images that were downloaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539c509d-4744-4e5e-9c87-7afda78a5450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (5404, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>20141006T000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2070</td>\n",
       "      <td>8893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>98058</td>\n",
       "      <td>47.4388</td>\n",
       "      <td>-122.162</td>\n",
       "      <td>2390</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>20140821T000000</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2900</td>\n",
       "      <td>6730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1830</td>\n",
       "      <td>1070</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6784</td>\n",
       "      <td>-122.285</td>\n",
       "      <td>2370</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>20140815T000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3770</td>\n",
       "      <td>10893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3770</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5646</td>\n",
       "      <td>-122.129</td>\n",
       "      <td>3710</td>\n",
       "      <td>9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>20150331T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4560</td>\n",
       "      <td>14608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4560</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.6995</td>\n",
       "      <td>-122.228</td>\n",
       "      <td>4050</td>\n",
       "      <td>14226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>20140714T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>5376</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6647</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>2250</td>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0  2591820310  20141006T000000         4       2.25         2070      8893   \n",
       "1  7974200820  20140821T000000         5       3.00         2900      6730   \n",
       "2  7701450110  20140815T000000         4       2.50         3770     10893   \n",
       "3  9522300010  20150331T000000         3       3.50         4560     14608   \n",
       "4  9510861140  20140714T000000         3       2.50         2550      5376   \n",
       "\n",
       "   floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0     2.0           0     0          4      8        2070              0   \n",
       "1     1.0           0     0          5      8        1830           1070   \n",
       "2     2.0           0     2          3     11        3770              0   \n",
       "3     2.0           0     2          3     12        4560              0   \n",
       "4     2.0           0     0          3      9        2550              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1986             0    98058  47.4388 -122.162           2390   \n",
       "1      1977             0    98115  47.6784 -122.285           2370   \n",
       "2      1997             0    98006  47.5646 -122.129           3710   \n",
       "3      1990             0    98034  47.6995 -122.228           4050   \n",
       "4      2004             0    98052  47.6647 -122.083           2250   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        7700  \n",
       "1        6283  \n",
       "2        9685  \n",
       "3       14226  \n",
       "4        4050  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_IMG_DIR = \"../data/images/test\"\n",
    "TEST_TAB_PATH = \"../data/raw/test.csv\"\n",
    "\n",
    "test_df = pd.read_csv(TEST_TAB_PATH)\n",
    "\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3700cc5-52cc-45b3-baef-87693818b238",
   "metadata": {},
   "source": [
    "The test dataset shape confirms the number of properties for which\n",
    "predictions must be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546dc02-a235-4e51-a562-9dc3e3b4b832",
   "metadata": {},
   "source": [
    "## 3. CNN Feature Extractor\n",
    "\n",
    "The same pretrained ResNet-18 architecture used during training is\n",
    "initialized to extract satellite image embeddings for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04ed3e9-76ef-4dcf-b703-9f89ae02561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "cnn.fc = nn.Identity()\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4c92b-5ba0-4aee-8659-5d3b39c929f7",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing\n",
    "\n",
    "Satellite images are resized and normalized using ImageNet statistics\n",
    "to ensure consistency with the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0a9717-fea8-4473-bc40-f8970c7e9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81722893-0ab3-4d78-b0cc-85c947514f5f",
   "metadata": {},
   "source": [
    "## 5. Robust Embedding Extraction\n",
    "\n",
    "A safe embedding extraction function is used to handle potential\n",
    "missing or corrupted images during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb8542b-f61a-4439-ba84-90000bbb3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding_safe(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = transform(img).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = cnn(x).squeeze().numpy()\n",
    "\n",
    "        return emb\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da102f81-733c-431a-b962-5938a996f9bf",
   "metadata": {},
   "source": [
    "## 6. Extracting Test Image Embeddings\n",
    "\n",
    "Satellite image embeddings are extracted for each property in the\n",
    "test dataset. Only valid image ID pairs are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf3f2ad-4cc5-41ba-8de4-117dcabf78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5404/5404 [01:11<00:00, 75.74it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "valid_ids = []\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    img_path = f\"{TEST_IMG_DIR}/{row['id']}.png\"\n",
    "    emb = extract_embedding_safe(img_path)\n",
    "\n",
    "    if emb is not None:\n",
    "        embeddings.append(emb)\n",
    "        valid_ids.append(row[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0136374-2542-4d99-a37e-0e60dd9ff2ab",
   "metadata": {},
   "source": [
    "## 7. Creating the Embedding Matrix\n",
    "\n",
    "Extracted embeddings are stored in a DataFrame with one 512-dimensional\n",
    "vector per property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b77cf69-50b4-48cf-ae5d-2d5e1f6a1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (5404, 513)\n"
     ]
    }
   ],
   "source": [
    "emb_df = pd.DataFrame(\n",
    "    embeddings,\n",
    "    columns=[f\"img_emb_{i}\" for i in range(512)]\n",
    ")\n",
    "\n",
    "emb_df[\"id\"] = valid_ids\n",
    "\n",
    "print(\"Test embeddings shape:\", emb_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67997e-c81b-45f3-9749-57d66905c274",
   "metadata": {},
   "source": [
    "## 8. Integrity Check: Duplicate Embeddings\n",
    "\n",
    "We explicitly check for duplicate property IDs to ensure that each\n",
    "test property is represented exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd06fe49-28ea-4538-bc42-b4ff9b0e6bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate embedding IDs: 8\n"
     ]
    }
   ],
   "source": [
    "dup_ids = emb_df[\"id\"][emb_df[\"id\"].duplicated()]\n",
    "print(\"Duplicate embedding IDs:\", dup_ids.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf795333-6c55-4602-af74-12d9f94035f4",
   "metadata": {},
   "source": [
    "Duplicate embeddings, if any, are removed to maintain a one to one\n",
    "mapping between property IDs and feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48508a24-620c-4170-a5d7-00993d181a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings after dedup: (5396, 513)\n",
      "Unique embedding IDs: 5396\n"
     ]
    }
   ],
   "source": [
    "emb_df = emb_df.drop_duplicates(subset=\"id\", keep=\"first\")\n",
    "\n",
    "print(\"Embeddings after dedup:\", emb_df.shape)\n",
    "print(\"Unique embedding IDs:\", emb_df[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da05e0-aa56-4d85-9cdd-22b9a6a569a7",
   "metadata": {},
   "source": [
    "## 9. Aligning Tabular and Visual Features\n",
    "\n",
    "The tabular test dataset is filtered to include only properties with\n",
    "valid satellite image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12d39e7-ead9-499a-b3f1-49dae12d93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test data shape: (5404, 20)\n"
     ]
    }
   ],
   "source": [
    "test_df_mm = test_df[test_df[\"id\"].isin(valid_ids)].copy()\n",
    "\n",
    "print(\"Filtered test data shape:\", test_df_mm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c90862-3976-43f6-a720-2d68fdf4647c",
   "metadata": {},
   "source": [
    "## 10. Constructing the Multimodal Test Dataset\n",
    "\n",
    "Tabular features and image embeddings are merged using property IDs\n",
    "to form the final multimodal feature matrix for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cc87df-bb54-4110-94b3-3a9e6191713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test multimodal shape: (5404, 532)\n"
     ]
    }
   ],
   "source": [
    "full_test_df = test_df_mm.merge(emb_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "print(\"Final test multimodal shape:\", full_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e22e0-1f50-4007-8f54-2703b12153e9",
   "metadata": {},
   "source": [
    "## 11. Preparing Features for Prediction\n",
    "\n",
    "Non predictive columns such as identifiers and timestamps are removed\n",
    "before passing features to the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77fbde82-5194-4095-8cf9-2cd8c73264d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (5404, 530)\n"
     ]
    }
   ],
   "source": [
    "X_test = full_test_df.drop(columns=[\"id\", \"date\"])\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7e96d-074d-4d47-9b67-b3e698b6fd30",
   "metadata": {},
   "source": [
    "## 12. Loading the Trained Multimodal Model\n",
    "\n",
    "The trained XGBoost multimodal model is loaded from disk for test-time\n",
    "inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030a7acc-3bfa-42d2-925a-d71f7e829651",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mm = joblib.load(\"../models/xgb_multimodal.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889567d-369c-44a2-a41a-5ad794799cca",
   "metadata": {},
   "source": [
    "## 13. Generating Test Predictions\n",
    "\n",
    "The multimodal model is used to predict property prices for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786fa984-72b9-46e5-bc7c-c5e3ab94d1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 347365.2 ,  805935.25, 1107798.5 , 1927297.8 ,  714824.06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = xgb_mm.predict(X_test)\n",
    "\n",
    "test_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b6b8f-bea9-4001-82d7-149ead834293",
   "metadata": {},
   "source": [
    "## 14. Creating the Submission File\n",
    "\n",
    "Predictions are combined with property IDs to create the final\n",
    "submission file in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3ebad0-07a0-4328-b463-5e932dd32907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>3.473652e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>8.059352e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>1.107798e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>1.927298e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>7.148241e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  predicted_price\n",
       "0  2591820310     3.473652e+05\n",
       "1  7974200820     8.059352e+05\n",
       "2  7701450110     1.107798e+06\n",
       "3  9522300010     1.927298e+06\n",
       "4  9510861140     7.148241e+05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": full_test_df[\"id\"],\n",
    "    \"predicted_price\": test_preds\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541cb79-665c-4e76-b507-e15cf2650e31",
   "metadata": {},
   "source": [
    "## 15. Saving Predictions\n",
    "\n",
    "The submission file is saved as a CSV for upload to the evaluation portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a06c57f-1c57-44cf-87ab-6f3b08a5c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to: ../submissions/23119016_final.csv\n"
     ]
    }
   ],
   "source": [
    "SUB_PATH = \"../submissions/23119016_final.csv\"\n",
    "submission.to_csv(SUB_PATH, index=False)\n",
    "\n",
    "print(\"Saved submission to:\", SUB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33ec6f-0921-49a7-a79c-0239f633608e",
   "metadata": {},
   "source": [
    "## 16. Final Validation Checks\n",
    "\n",
    "We verify the submission shape and ensure that no missing values\n",
    "are present in the prediction file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2afabc76-00bd-46fa-97e3-c44f2433d789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5404, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0d637a-8822-434b-930e-6c04730a5d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "predicted_price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e2dc3-04d4-4dc7-88e2-04688e31f128",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completes the end to end multimodal inference pipeline.\n",
    "Satellite image embeddings and tabular features are successfully combined\n",
    "to generate price predictions for all test properties. The resulting\n",
    "submission file is validated and ready for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3d3db-b8e5-48a0-a5a1-86fad9eb2c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
